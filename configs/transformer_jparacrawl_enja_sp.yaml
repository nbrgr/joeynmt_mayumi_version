name: "jparacrawl-enja-sp-transformer"

data:
  src: "en"
  trg: "ja"
  train: "/scratch5t/ohta/jparacrawl/train"
  dev: "/scratch5t/ohta/iwslt17/tst2016"
  test: "/scratch5t/ohta/iwslt17/tst2017"
  random_train_subset: -1
  level: "bpe"
  lowercase: False
  max_sent_length: 500
  src_voc_min_freq: 2
  src_voc_limit: 5000
  trg_voc_min_freq: 2
  trg_voc_limit: 9000
  src_vocab: "/scratch5t/ohta/jparacrawl/volt/vocab.en.tsv"
  trg_vocab: "/scratch5t/ohta/jparacrawl/volt/vocab.ja.tsv"
  spm_src:
    model_file: "/scratch5t/ohta/jparacrawl/volt/spm10000.en.model"
    enable_sampling: True
  spm_trg:
    model_file: "/scratch5t/ohta/jparacrawl/volt/spm9000.ja.model"
    enable_sampling: True

testing:
  beam_size: 6
  alpha: 1.0
  postproccess: True
  bpe_type: "sentencepiece"
  sacrebleu:
    remove_whitespace: False
    tokenize: "ja-mecab"

training:
  random_seed: 42
  optimizer: "adam"
  normalization: "tokens"
  adam_betas: [0.9, 0.98]
  scheduling: "warmupinversesquareroot"
  loss: "crossentropy"
  learning_rate: 0.001
  learning_rate_min: 1.0e-09
  learning_rate_warmup: 4000
  clip_grad_norm: 1.0
  weight_decay: 0.0
  label_smoothing: 0.1
  batch_multiplier: 8
  batch_size: 4096 # 2048 per device
  batch_type: "token"
  early_stopping_metric: "eval_metric"
  epochs: 10
  validation_freq: 500
  logging_freq: 100
  eval_metric: "bleu"
  model_dir: "/scratch12t/ohta/models/jparacrawl_enja_sp_transformer_2gpu"
  overwrite: True
  shuffle: True
  use_cuda: True
  fp16: False
  max_output_length: 100
  print_valid_sents: [2000, 2001, 2002, 2003, 2004]
  keep_best_ckpts: 5
  num_workers: 0

model:
  initializer: "xavier"
  embed_initializer: "xavier"
  embed_init_gain: 1.0
  init_gain: 1.0
  bias_initializer: "zeros"
  tied_embeddings: False
  tied_softmax: False
  encoder:
    type: "transformer"
    num_layers: 8
    num_heads: 16
    embeddings:
      embedding_dim: 1024
      scale: True
      dropout: 0.
    hidden_size: 1024
    ff_size: 4096
    dropout: 0.3
  decoder:
    type: "transformer"
    num_layers: 6
    num_heads: 16
    embeddings:
      embedding_dim: 1024
      scale: True
      dropout: 0.
    hidden_size: 1024
    ff_size: 4096
    dropout: 0.3
